{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:UTF-8\n",
    "import random as rd\n",
    "import numpy as np\n",
    "from math import pow\n",
    "from math import log\n",
    "import tifffile as tiff\n",
    "import tensorflow as tf\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_zhenye(file_name):\n",
    "    img_data=tiff.imread(file_name)\n",
    "    img_data=np.rollaxis(img_data,0,3)\n",
    "    img_data=np.reshape(img_data,(-1,12))\n",
    "    m,n=np.shape(img_data)\n",
    "    data=[]\n",
    "    for i in range(m):\n",
    "        b=[]\n",
    "        for j in range(n):\n",
    "            b.append(round(img_data[i][j],3))\n",
    "        data.append(b)  \n",
    "    label=np.zeros(m)\n",
    "    label=tf.constant(label,dtype=tf.int32)\n",
    "    label= tf.one_hot(label,4)\n",
    "    sess=tf.Session()\n",
    "    label=label.eval(session=sess)\n",
    "    label=label.tolist()\n",
    "    return data,label\n",
    "\n",
    "def load_data_kuoye(file_name):\n",
    "    img_data=tiff.imread(file_name)\n",
    "    img_data=np.rollaxis(img_data,0,3)\n",
    "    img_data=np.reshape(img_data,(-1,12))\n",
    "    m,n=np.shape(img_data)\n",
    "    data=[]\n",
    "    for i in range(m):\n",
    "        b=[]\n",
    "        for j in range(n):\n",
    "            b.append(round(img_data[i][j],3))\n",
    "        data.append(b)  \n",
    "    label=np.zeros(m)+1\n",
    "    label=tf.constant(label,dtype=tf.int32)\n",
    "    label= tf.one_hot(label,4)\n",
    "    sess=tf.Session()\n",
    "    label=label.eval(session=sess)\n",
    "    label=label.tolist()\n",
    "    return data,label\n",
    "\n",
    "def load_data_hunjiao(file_name):\n",
    "    img_data=tiff.imread(file_name)\n",
    "    img_data=np.rollaxis(img_data,0,3)\n",
    "    img_data=np.reshape(img_data,(-1,12))\n",
    "    m,n=np.shape(img_data)\n",
    "    data=[]\n",
    "    for i in range(m):\n",
    "        b=[]\n",
    "        for j in range(n):\n",
    "            b.append(round(img_data[i][j],3))\n",
    "        data.append(b)  \n",
    "    label=np.zeros(m)+2\n",
    "    label=tf.constant(label,dtype=tf.int32)\n",
    "    label= tf.one_hot(label,4)\n",
    "    sess=tf.Session()\n",
    "    label=label.eval(session=sess)\n",
    "    label=label.tolist()\n",
    "    return data,label\n",
    "\n",
    "def load_data_qita(file_name):\n",
    "    img_data=tiff.imread(file_name)\n",
    "    img_data=np.rollaxis(img_data,0,3)\n",
    "    img_data=np.reshape(img_data,(-1,12))\n",
    "    m,n=np.shape(img_data)\n",
    "    data=[]\n",
    "    for i in range(m):\n",
    "        b=[]\n",
    "        for j in range(n):\n",
    "            b.append(round(img_data[i][j],3))\n",
    "        data.append(b)  \n",
    "    label=np.zeros(m)+3\n",
    "    label=tf.constant(label,dtype=tf.int32)\n",
    "    label= tf.one_hot(label,4)\n",
    "    sess=tf.Session()\n",
    "    label=label.eval(session=sess)\n",
    "    label=label.tolist()\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhenye_data1,zhenye_label1=load_data_zhenye(\"C:/Users/chris/Desktop/0411_12BAND/zhenye1.tif\")\n",
    "zhenye_data2,zhenye_label2=load_data_zhenye(\"C:/Users/chris/Desktop/0411_12BAND/zhenye2.tif\")\n",
    "zhenye_data3,zhenye_label3=load_data_zhenye(\"C:/Users/chris/Desktop/0411_12BAND/zhenye3.tif\")\n",
    "zhenye_data4,zhenye_label4=load_data_zhenye(\"C:/Users/chris/Desktop/0411_12BAND/zhenye4.tif\")\n",
    "kuoye_data1,kuoye_label1=load_data_kuoye(\"C:/Users/chris/Desktop/0411_12BAND/kuoye1.tif\")\n",
    "kuoye_data2,kuoye_label2=load_data_kuoye(\"C:/Users/chris/Desktop/0411_12BAND/kuoye2.tif\")\n",
    "kuoye_data3,kuoye_label3=load_data_kuoye(\"C:/Users/chris/Desktop/0411_12BAND/kuoye3.tif\")\n",
    "kuoye_data4,kuoye_label4=load_data_kuoye(\"C:/Users/chris/Desktop/0411_12BAND/kuoye4.tif\")\n",
    "hunjiao_data1,hunjiao_label1=load_data_hunjiao(\"C:/Users/chris/Desktop/0411_12BAND/hunjiao1.tif\")\n",
    "hunjiao_data2,hunjiao_label2=load_data_hunjiao(\"C:/Users/chris/Desktop/0411_12BAND/hunjiao2.tif\")\n",
    "hunjiao_data3,hunjiao_label3=load_data_hunjiao(\"C:/Users/chris/Desktop/0411_12BAND/hunjiao3.tif\")\n",
    "hunjiao_data4,hunjiao_label4=load_data_hunjiao(\"C:/Users/chris/Desktop/0411_12BAND/hunjiao4.tif\")\n",
    "qita1_data,qita1_label=load_data_qita(\"C:/Users/chris/Desktop/0411_12BAND/qita1.tif\")\n",
    "qita2_data,qita2_label=load_data_qita(\"C:/Users/chris/Desktop/0411_12BAND/qita2.tif\")\n",
    "qita3_data,qita3_label=load_data_qita(\"C:/Users/chris/Desktop/0411_12BAND/qita3.tif\")\n",
    "qita4_data,qita4_label=load_data_qita(\"C:/Users/chris/Desktop/0411_12BAND/qita4.tif\")\n",
    "qita5_data,qita5_label=load_data_qita(\"C:/Users/chris/Desktop/0411_12BAND/qita5.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= np.array(zhenye_data1+zhenye_data2+zhenye_data3+zhenye_data4+kuoye_data1+kuoye_data2+kuoye_data3+kuoye_data4+hunjiao_data1+hunjiao_data2+hunjiao_data3+hunjiao_data4+qita1_data+qita2_data+qita3_data+qita4_data+qita5_data)\n",
    "train_label=np.array(zhenye_label1+zhenye_label2+zhenye_label3+zhenye_label4+kuoye_label1+kuoye_label2+kuoye_label3+kuoye_label4+hunjiao_label1+hunjiao_label2+hunjiao_label3+hunjiao_label4+ qita1_label+qita2_label+qita3_label+qita4_label+qita5_label)\n",
    "train=(train_data,train_label)\n",
    "test_data=load_data_zhenye(\"C:/Users/chris/Desktop/0411_12BAND/jy_20180411_cut3c_12band.tif\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x=tf.placeholder(tf.float32,[None,3*4])#None表示图片张数，input_x每个元素介于0-1\n",
    "output_y=tf.placeholder(tf.int32,[None,4])\n",
    "input_x_images=tf.reshape(input_x,[-1,3,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1=tf.layers.conv2d(inputs=input_x_images,#形状【3，4，1】\n",
    "                       filters=32,#输出的深度是32\n",
    "                       kernel_size=[2,2],#过滤器在二维的大小\n",
    "                       strides=1,#步长\n",
    "                       padding='same',#same表示输出大小不变，因此需要在外围补零2圈\n",
    "                       activation=tf.nn.relu #激活函数是Relu\n",
    "                      )#形状【3，4，32】\n",
    "pool1=tf.layers.max_pooling2d(inputs=conv1,\n",
    "                             pool_size=[2,2],\n",
    "                             strides=1)#形状【2，3，32】\n",
    "conv2=tf.layers.conv2d(inputs=pool1,\n",
    "                       filters=64,\n",
    "                       kernel_size=[2,2],\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       activation=tf.nn.relu \n",
    "                      )#形状【2，3，64】\n",
    "pool2=tf.layers.max_pooling2d(inputs=conv2,\n",
    "                             pool_size=[2,2],\n",
    "                             strides=1)#形状【1，2，64】 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#平坦化（flat)\n",
    "flat=tf.reshape(pool2,[-1,1*2*64])#-1根据后面的参数推算此处的值\n",
    "#1024个神经元的全连接层\n",
    "dense=tf.layers.dense(inputs=flat,units=1024,activation=tf.nn.relu)\n",
    "#dropout丢弃\n",
    "dropout=tf.layers.dropout(inputs=dense,rate=0.5)\n",
    "#10个神经元的全连接层，这里不用激活函数来做非线性化了\n",
    "logits=tf.layers.dense(inputs=dropout,units=4)#输出，形状【1，1，4】\n",
    "#计算误差(先Softmax再计算交叉熵cross_entropy的方法）\n",
    "#softmax把一个k维的real value向量[a1,a2,a3,a4….]映射成一个[b1,b2,b3,b4….]\n",
    "#其中bi是一个0-1的常数，然后可以根据bi的大小来进行多分类的任务，如取权重最大的一维。\n",
    "loss=tf.losses.softmax_cross_entropy(onehot_labels=output_y,logits=logits)\n",
    "#用Adam优化器来最小化误差，学习率为0.001\n",
    "train_op=tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "#计算预测值和实际标签的匹配程度,会创建两个局部变量\n",
    "accuracy=tf.metrics.accuracy(labels=tf.argmax(output_y,axis=1),\n",
    "                             #argmax返回张量最大值的下标\n",
    "                             predictions=tf.argmax(logits,axis=1))[1]#updata_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0,train loss=37.0939,[Test accuracy=0.17]\n",
      "step=100,train loss=0.4844,[Test accuracy=0.48]\n",
      "step=200,train loss=0.4050,[Test accuracy=0.59]\n",
      "step=300,train loss=0.3777,[Test accuracy=0.65]\n",
      "step=400,train loss=0.3764,[Test accuracy=0.69]\n",
      "step=500,train loss=0.4010,[Test accuracy=0.71]\n",
      "step=600,train loss=0.3580,[Test accuracy=0.73]\n",
      "step=700,train loss=0.3917,[Test accuracy=0.74]\n",
      "step=800,train loss=0.3353,[Test accuracy=0.75]\n",
      "step=900,train loss=0.3177,[Test accuracy=0.76]\n",
      "step=1000,train loss=0.3429,[Test accuracy=0.77]\n",
      "step=1100,train loss=0.2911,[Test accuracy=0.78]\n",
      "step=1200,train loss=0.2798,[Test accuracy=0.79]\n",
      "step=1300,train loss=0.3093,[Test accuracy=0.79]\n",
      "step=1400,train loss=0.2834,[Test accuracy=0.80]\n",
      "step=1500,train loss=0.2689,[Test accuracy=0.80]\n",
      "step=1600,train loss=0.2680,[Test accuracy=0.81]\n",
      "step=1700,train loss=0.2472,[Test accuracy=0.81]\n",
      "step=1800,train loss=0.2749,[Test accuracy=0.82]\n",
      "step=1900,train loss=0.2514,[Test accuracy=0.82]\n",
      "step=2000,train loss=0.2671,[Test accuracy=0.82]\n",
      "[0 0 0 ... 3 3 3] inferenced train numbers\n",
      "[0 0 0 ... 3 3 3] real train numbers\n",
      "[3 3 3 ... 3 3 2] interenced test numbers\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "#初始化变量：全局和局部\n",
    "init=tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "sess.run(init)\n",
    "for i in range(2001):\n",
    "    batch=train\n",
    "    train_loss,train_op_=sess.run([loss,train_op],{input_x:batch\n",
    "[0],output_y:batch[1]})\n",
    "    if i%100==0:\n",
    "        test_accuracy=sess.run(accuracy,{input_x:train_data,output_y:train_label})\n",
    "        print(('step=%d,train loss=%.4f,[Test accuracy=%.2f]')\\\n",
    "               %(i,train_loss,test_accuracy))              \n",
    "#打印预测值和真实值\n",
    "train_output=sess.run(logits,{input_x:train_data})                             \n",
    "interenced_train=np.argmax(train_output,1)   \n",
    "print(interenced_train,'inferenced train numbers')\n",
    "real=np.argmax(train_label,1)\n",
    "print(real,'real train numbers') \n",
    "test_output=sess.run(logits,{input_x:test_data})\n",
    "interenced_test=np.argmax(test_output,1)\n",
    "print(interenced_test,'interenced test numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8883620689655173"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=0.0\n",
    "for i in range(len(real)):\n",
    "    if interenced_train[i]==real[i]:\n",
    "        corr+=1\n",
    "corr/len(real)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144058,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interenced_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=interenced_test.reshape(323,446)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323, 446)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('C:/Users/chris/Desktop/0411_12BAND/jy_cut3c_forestclass_4.tif',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2320, 12)\n",
      "(2320, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train[0].shape)\n",
    "print(train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144058, 12)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
